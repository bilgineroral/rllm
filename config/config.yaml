# Model config
d_protein: 1152
d_model: 1024
num_heads: 8 # Number of attention heads in cross attention blocks

rllm_dropout: 0.2
gpt_dropout: 0.1

tokenizer_path: "./tokenizer"
gpt_weights_path: "./GenerRNA/checkpoint.pt"

# Training Configuration
batch_size: 32
num_epochs: 5
rllm_learning_rate: 1.0e-3
gpt_learning_rate: 1.0e-4
checkpoint_interval: 4000  # Validate and save model every n iterations
plot_interval: 200        # Plot every n iterations
early_stopping: True
early_stopping_patience: 8 # counted every checkpoint_interval
num_workers_train: 8          # Number of workers for data loader
num_workers_val: 4          # Number of workers for data loader

warmup_ratio: 0.1       # warmup steps = warmup_ratio * total_steps
optimizer_weight_decay: 0.01

# Data Paths
data_paths:
  protein_data_path: "./dataset/protein" # path to protein embeddings folder
  pairs_train_path: "./dataset/train.txt"
  pairs_val_path: "./dataset/val.txt"
  pairs_test_path: "./dataset/test.txt"

# Directories
output_paths:
  checkpoint_dir: "./checkpoints"
  plots_dir: "./plots"
  train_losses_path: "./train_losses.txt"
  val_losses_path: "./val_losses.txt"
  train_perplexities_path: "./train_perplexities.txt"
  val_perplexities_path: "./val_perplexities.txt"
  log_path: "./train.log"
